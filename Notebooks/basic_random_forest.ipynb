{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab nbagg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from os import listdir\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "from importlib import reload\n",
    "import utils\n",
    "import pickle\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from scipy.stats import mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'utils' from 'C:\\\\Users\\\\efreiling\\\\Desktop\\\\new_york_311\\\\Notebooks\\\\utils.py'>"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reload(utils)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the data\n",
    "- We are only dealing with 10% of the data for memory and time purposes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = Path('../../data/new_york_311')\n",
    "data_path = data_folder / 'data_311.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\efreiling\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3058: DtypeWarning: Columns (31,32) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "orig_data = pd.read_csv(data_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop Certain Columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the main columns that would be useful is resolution description. Depending on the scenario or application this could be considered to have leakage. However, if we were to include it in the features, we can try several approaches:\n",
    "- Drop stop words\n",
    "- Convert words to vectors using word2vec, take the average of the vectors\n",
    "- Sklearn HashingVectorizer\n",
    "- Use Tf-Idf to find important words, use word2vec on top N words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_cols = [\n",
    "    'unique_key',                     # If interested in finding hidden leakage, investigate this column\n",
    "    'agency_name',                    # Redundant to agancy\n",
    "    'descriptor',                     # This gives away the complaint type, leakage\n",
    "    'incident_address',               # Didnt want street numbers\n",
    "    'bbl',                            # We already have enough goelocaions\n",
    "    'location',                       # Redundant to Lat and Lng\n",
    "    'resolution_action_updated_date', # caused errors\n",
    "    'resolution_description'          # Probably very useful but not enough time to use and maybe leakage\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = utils.drop_useless_cols(orig_data, drop_cols)       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter Rows\n",
    "- Only use rows that contain the 130 complaint types\n",
    "- Filter rows that are all NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = utils.filter_rows(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Continuous, Categorical, Date Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "cont_cols = [\n",
    "    'x_coordinate_state_plane',\n",
    "    'y_coordinate_state_plane',\n",
    "    'latitude',\n",
    "    'longitude',\n",
    "    'time_to_close',\n",
    "    'due_len',\n",
    "    'time_over'\n",
    "]\n",
    "cat_cols = [\n",
    "    'agency',\n",
    "    'borough',\n",
    "    'location_type',\n",
    "    'incident_zip',\n",
    "    'street_name',\n",
    "    'cross_street_1',\n",
    "    'cross_street_2',\n",
    "    'intersection_street_1',\n",
    "    'intersection_street_2',\n",
    "    'address_type',\n",
    "    'city',\n",
    "    'landmark',\n",
    "    'facility_type',\n",
    "    'status',\n",
    "    'community_board',\n",
    "    'open_data_channel_type',\n",
    "    'park_facility_name',\n",
    "    'park_borough',\n",
    "    'vehicle_type',\n",
    "    'taxi_company_borough',\n",
    "    'taxi_pick_up_location',\n",
    "    'bridge_highway_name',\n",
    "    'bridge_highway_direction',\n",
    "    'road_ramp',\n",
    "    'bridge_highway_segment',\n",
    "]\n",
    "date_cols = [\n",
    "    'created_date',\n",
    "    'closed_date',\n",
    "    'due_date',\n",
    "]\n",
    "dep_var = ['complaint_type']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process Date Columns\n",
    "- Add columns for time elapsed between dates\n",
    "- Add features for day of week, end of year, etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    " df, cont_cols, cat_cols = utils.process_date_cols(df, cont_cols, cat_cols, date_cols, dep_var)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process Continuous Columns\n",
    "- Fill in missing values with the median of the column, then add another feature that idicates which rows had missing values\n",
    "- Normalize Z-score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "df, cont_cols, cat_cols = utils.process_cont_cols(df, cont_cols, cat_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process Categorical Columns\n",
    "- Ordinal Encoding for columns with number of classes greater than 20\n",
    "- One hot encoding for columns with number of classes 20 or less"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "df, cat_cols, label_encoders = utils.process_cat_cols(df, cat_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split Dataframe into Features and Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y, label_encoders = utils.split_target(df, dep_var[0], label_encoders)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train a Random Forest Classifier and Compare to Naive Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 45\n",
    "train_x, test_x, train_y, test_y = train_test_split(x, y, test_size=0.2, random_state=seed)\n",
    "clf = RandomForestClassifier(max_depth=4, random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\efreiling\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "                       max_depth=4, max_features='auto', max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=10,\n",
       "                       n_jobs=None, oob_score=False, random_state=45, verbose=0,\n",
       "                       warm_start=False)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = clf.predict(test_x)\n",
    "correct_loc = np.where(preds == test_y)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "perc_correct = len(correct_loc) / len(preds)\n",
    "perc_correct_naive = len(np.where(test_y == mode(test_y)[0][0])[0]) / len(test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:\n",
      "Random Forest: 0.3709, Mode: 0.0819\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy:')\n",
    "print(f'Random Forest: {round(perc_correct, 4)}, Mode: {round(perc_correct_naive, 4)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Look at Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "importances = clf.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = np.argsort(importances)[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('location_type', 0.13413712905088399),\n",
       " ('facility_type=missing', 0.08736788701911924),\n",
       " ('agency=NYPD', 0.06943029322972669),\n",
       " ('due_Elapsed', 0.059404650462870266),\n",
       " ('due_len_missing=0.0', 0.04644923446253123),\n",
       " ('created_Elapsed', 0.045418975289304775),\n",
       " ('due_Dayofyear', 0.04341417287545382),\n",
       " ('address_type=INTERSECTION', 0.039566238582605),\n",
       " ('time_over', 0.037816529474270874),\n",
       " ('agency=DOT', 0.03548596458764168),\n",
       " ('cross_street_2', 0.02782223136862763),\n",
       " ('facility_type=Precinct', 0.026923240392949195),\n",
       " ('time_to_close', 0.02299322794584701),\n",
       " ('street_name', 0.022283453225225958),\n",
       " ('status=Closed', 0.01853681468623733),\n",
       " ('closed_Elapsed', 0.01832531226289153),\n",
       " ('facility_type=DSNY Garage', 0.01786498417948957),\n",
       " ('borough=Unspecified', 0.017473911383111107),\n",
       " ('city', 0.014650682921886052),\n",
       " ('y_coordinate_state_plane_missing=0.0', 0.013212402361475247),\n",
       " ('due_Dayofweek=missing', 0.013122251922591158),\n",
       " ('time_over_missing=1.0', 0.012595844129405395),\n",
       " ('intersection_street_1', 0.01200424282532837),\n",
       " ('taxi_pick_up_location', 0.011730899194621756),\n",
       " ('longitude_missing=0.0', 0.0098468087092736),\n",
       " ('agency=HPD', 0.009238418303595907),\n",
       " ('due_Month=missing', 0.008715322191860875),\n",
       " ('incident_zip', 0.00811064010735307),\n",
       " ('due_Year=missing', 0.008082129585583235),\n",
       " ('open_data_channel_type=UNKNOWN', 0.007839315133802548),\n",
       " ('agency=HRA', 0.0073571311326678535),\n",
       " ('agency=DHS', 0.0066534892731049625),\n",
       " ('park_borough=Unspecified', 0.00650580501308042),\n",
       " ('agency=TLC', 0.005943183272894408),\n",
       " ('due_len', 0.005571673128982201),\n",
       " ('agency=DPR', 0.005289415219478489),\n",
       " ('latitude_missing=1.0', 0.0051622424521432795),\n",
       " ('agency=DOF', 0.0045721651005938505),\n",
       " ('address_type=missing', 0.004061389496460296),\n",
       " ('park_facility_name', 0.0037104467287777123),\n",
       " ('due_Week', 0.0032482754410523506),\n",
       " ('address_type=ADDRESS', 0.00317125803522084),\n",
       " ('open_data_channel_type=OTHER', 0.002875694610922654),\n",
       " ('latitude_missing=0.0', 0.002820110827194511),\n",
       " ('community_board', 0.0026819972622278503),\n",
       " ('latitude', 0.002364564076055299),\n",
       " ('park_borough=MANHATTAN', 0.0023148209479021305),\n",
       " ('due_len_missing=1.0', 0.0022888507363930974),\n",
       " ('open_data_channel_type=MOBILE', 0.0022857163221989872),\n",
       " ('borough=QUEENS', 0.0022112961894421527),\n",
       " ('agency=DSNY', 0.002142484552304734),\n",
       " ('created_Year=2011', 0.0021316659126913817),\n",
       " ('x_coordinate_state_plane_missing=0.0', 0.001740505917544635),\n",
       " ('closed_Dayofweek=6.0', 0.0015913403591384632),\n",
       " ('closed_Year=2017.0', 0.0014695000687777403),\n",
       " ('open_data_channel_type=ONLINE', 0.0013441650768542012),\n",
       " ('borough=BRONX', 0.001001122297240827),\n",
       " ('open_data_channel_type=PHONE', 0.0009739588290608578),\n",
       " ('closed_Dayofweek=missing', 0.0009200409434138345),\n",
       " ('y_coordinate_state_plane_missing=1.0', 0.0009003152180507929),\n",
       " ('created_Dayofyear', 0.0008966705028036195),\n",
       " ('due_Year=2010.0', 0.000653208204319175),\n",
       " ('created_Month=7', 0.0006107492441774939),\n",
       " ('closed_Year=2010.0', 0.0006003759912765522),\n",
       " ('created_Month=12', 0.0003828601354961169),\n",
       " ('intersection_street_2', 0.00030535142243663687),\n",
       " ('longitude', 0.0002839314080883724),\n",
       " ('due_Month=3.0', 0.0002790720355698368),\n",
       " ('time_to_close_missing=1.0', 0.00020769673321109676),\n",
       " ('x_coordinate_state_plane', 0.0002036901072640289),\n",
       " ('due_Year=2018.0', 0.00018379378249919954),\n",
       " ('cross_street_1', 0.00016701500463273163),\n",
       " ('closed_Year=2018.0', 5.775312079021165e-05),\n",
       " ('facility_type=School', 0.0),\n",
       " ('taxi_company_borough=MANHATTAN', 0.0),\n",
       " ('status=Pending', 0.0),\n",
       " ('status=Open', 0.0),\n",
       " ('taxi_company_borough=BROOKLYN', 0.0),\n",
       " ('taxi_company_borough=Bronx', 0.0),\n",
       " ('taxi_company_borough=Brooklyn', 0.0),\n",
       " ('status=In Progress', 0.0),\n",
       " ('status=Draft', 0.0),\n",
       " ('park_borough=QUEENS', 0.0),\n",
       " ('status=Closed - Testing', 0.0),\n",
       " ('created_Year=2018', 0.0),\n",
       " ('status=Assigned', 0.0),\n",
       " ('taxi_company_borough=Manhattan', 0.0),\n",
       " ('taxi_company_borough=QUEENS', 0.0),\n",
       " ('taxi_company_borough=Queens', 0.0),\n",
       " ('taxi_company_borough=BRONX', 0.0),\n",
       " ('status=Started', 0.0),\n",
       " ('status=Unassigned', 0.0),\n",
       " ('status=Unspecified', 0.0),\n",
       " ('status=missing', 0.0),\n",
       " ('open_data_channel_type=BRONX', 0.0),\n",
       " ('vehicle_type=missing', 0.0),\n",
       " ('vehicle_type=Green Taxi', 0.0),\n",
       " ('vehicle_type=Commuter Van', 0.0),\n",
       " ('vehicle_type=Car Service', 0.0),\n",
       " ('vehicle_type=Ambulette / Paratransit', 0.0),\n",
       " ('park_borough=missing', 0.0),\n",
       " ('created_Year=2016', 0.0),\n",
       " ('park_borough=STATEN ISLAND', 0.0),\n",
       " ('created_Year=2017', 0.0),\n",
       " ('park_borough=BRONX', 0.0),\n",
       " ('park_borough=BROOKLYN', 0.0),\n",
       " ('created_Year=2019', 0.0),\n",
       " ('borough=STATEN ISLAND', 0.0),\n",
       " ('created_Month=1', 0.0),\n",
       " ('created_Week', 0.0),\n",
       " ('created_Month=9', 0.0),\n",
       " ('closed_Is_month_start=false', 0.0),\n",
       " ('due_Day', 0.0),\n",
       " ('closed_Is_month_start=true', 0.0),\n",
       " ('closed_Dayofyear', 0.0),\n",
       " ('closed_Day', 0.0),\n",
       " ('closed_Week', 0.0),\n",
       " ('due_Is_quarter_start=false', 0.0),\n",
       " ('created_Day', 0.0),\n",
       " ('due_Is_quarter_start=true', 0.0),\n",
       " ('created_Month=10', 0.0),\n",
       " ('x_coordinate_state_plane_missing=1.0', 0.0),\n",
       " ('bridge_highway_segment', 0.0),\n",
       " ('bridge_highway_direction', 0.0),\n",
       " ('bridge_highway_name', 0.0),\n",
       " ('time_over_missing=0.0', 0.0),\n",
       " ('y_coordinate_state_plane', 0.0),\n",
       " ('landmark', 0.0),\n",
       " ('longitude_missing=1.0', 0.0),\n",
       " ('time_to_close_missing=0.0', 0.0),\n",
       " ('agency=3-1-1', 0.0),\n",
       " ('agency=DCA', 0.0),\n",
       " ('agency=DEP', 0.0),\n",
       " ('agency=DFTA', 0.0),\n",
       " ('address_type=PLACENAME', 0.0),\n",
       " ('address_type=LATLONG', 0.0),\n",
       " ('created_Month=11', 0.0),\n",
       " ('address_type=BLOCKFACE', 0.0),\n",
       " ('borough=missing', 0.0),\n",
       " ('taxi_company_borough=Staten Island', 0.0),\n",
       " ('borough=MANHATTAN', 0.0),\n",
       " ('borough=BROOKLYN', 0.0),\n",
       " ('created_Month=2', 0.0),\n",
       " ('created_Month=3', 0.0),\n",
       " ('agency=NYCEM', 0.0),\n",
       " ('created_Month=4', 0.0),\n",
       " ('created_Month=5', 0.0),\n",
       " ('agency=EDC', 0.0),\n",
       " ('created_Month=6', 0.0),\n",
       " ('agency=DOHMH', 0.0),\n",
       " ('agency=DOE', 0.0),\n",
       " ('agency=DOB', 0.0),\n",
       " ('created_Month=8', 0.0),\n",
       " ('taxi_company_borough=STATEN ISLAND', 0.0),\n",
       " ('created_Year=2012', 0.0),\n",
       " ('taxi_company_borough=missing', 0.0),\n",
       " ('closed_Month=2.0', 0.0),\n",
       " ('closed_Month=11.0', 0.0),\n",
       " ('closed_Month=10.0', 0.0),\n",
       " ('closed_Month=1.0', 0.0),\n",
       " ('created_Is_year_start=true', 0.0),\n",
       " ('created_Is_year_start=false', 0.0),\n",
       " ('closed_Is_year_start=true', 0.0),\n",
       " ('closed_Is_year_start=false', 0.0),\n",
       " ('created_Is_quarter_end=true', 0.0),\n",
       " ('created_Is_quarter_end=false', 0.0),\n",
       " ('created_Dayofweek=6', 0.0),\n",
       " ('created_Dayofweek=5', 0.0),\n",
       " ('created_Dayofweek=4', 0.0),\n",
       " ('created_Dayofweek=3', 0.0),\n",
       " ('created_Dayofweek=2', 0.0),\n",
       " ('created_Dayofweek=1', 0.0),\n",
       " ('created_Dayofweek=0', 0.0),\n",
       " ('closed_Is_quarter_end=true', 0.0),\n",
       " ('closed_Is_quarter_end=false', 0.0),\n",
       " ('created_Year=2014', 0.0),\n",
       " ('due_Dayofweek=6.0', 0.0),\n",
       " ('due_Dayofweek=5.0', 0.0),\n",
       " ('due_Dayofweek=4.0', 0.0),\n",
       " ('due_Dayofweek=3.0', 0.0),\n",
       " ('closed_Month=12.0', 0.0),\n",
       " ('closed_Month=3.0', 0.0),\n",
       " ('due_Dayofweek=1.0', 0.0),\n",
       " ('closed_Month=4.0', 0.0),\n",
       " ('created_Year=2010', 0.0),\n",
       " ('created_Year=2013', 0.0),\n",
       " ('due_Month=9.0', 0.0),\n",
       " ('due_Month=8.0', 0.0),\n",
       " ('due_Month=7.0', 0.0),\n",
       " ('due_Month=6.0', 0.0),\n",
       " ('due_Month=5.0', 0.0),\n",
       " ('due_Month=4.0', 0.0),\n",
       " ('due_Month=2.0', 0.0),\n",
       " ('due_Month=12.0', 0.0),\n",
       " ('due_Month=11.0', 0.0),\n",
       " ('due_Month=10.0', 0.0),\n",
       " ('due_Month=1.0', 0.0),\n",
       " ('due_Is_quarter_end=true', 0.0),\n",
       " ('due_Is_quarter_end=false', 0.0),\n",
       " ('due_Is_year_end=true', 0.0),\n",
       " ('due_Is_year_end=false', 0.0),\n",
       " ('closed_Month=missing', 0.0),\n",
       " ('closed_Month=9.0', 0.0),\n",
       " ('closed_Month=8.0', 0.0),\n",
       " ('closed_Month=7.0', 0.0),\n",
       " ('closed_Month=6.0', 0.0),\n",
       " ('closed_Month=5.0', 0.0),\n",
       " ('due_Dayofweek=2.0', 0.0),\n",
       " ('due_Dayofweek=0.0', 0.0),\n",
       " ('road_ramp=Ramp', 0.0),\n",
       " ('due_Year=2011.0', 0.0),\n",
       " ('due_Year=1900.0', 0.0),\n",
       " ('due_Is_month_end=true', 0.0),\n",
       " ('due_Is_month_end=false', 0.0),\n",
       " ('closed_Year=missing', 0.0),\n",
       " ('closed_Year=2020.0', 0.0),\n",
       " ('closed_Year=2019.0', 0.0),\n",
       " ('closed_Year=2016.0', 0.0),\n",
       " ('closed_Year=2015.0', 0.0),\n",
       " ('closed_Year=2014.0', 0.0),\n",
       " ('closed_Year=2013.0', 0.0),\n",
       " ('closed_Year=2012.0', 0.0),\n",
       " ('closed_Year=2011.0', 0.0),\n",
       " ('closed_Year=2009.0', 0.0),\n",
       " ('closed_Year=1900.0', 0.0),\n",
       " ('due_Is_year_start=true', 0.0),\n",
       " ('due_Is_year_start=false', 0.0),\n",
       " ('created_Is_year_end=true', 0.0),\n",
       " ('created_Is_year_end=false', 0.0),\n",
       " ('created_Is_month_end=true', 0.0),\n",
       " ('created_Is_month_end=false', 0.0),\n",
       " ('created_Is_month_start=true', 0.0),\n",
       " ('road_ramp=missing', 0.0),\n",
       " ('road_ramp=Roadway', 0.0),\n",
       " ('due_Year=2008.0', 0.0),\n",
       " ('due_Year=2012.0', 0.0),\n",
       " ('closed_Is_month_end=true', 0.0),\n",
       " ('due_Year=2013.0', 0.0),\n",
       " ('closed_Is_month_end=false', 0.0),\n",
       " ('due_Is_month_start=true', 0.0),\n",
       " ('due_Is_month_start=false', 0.0),\n",
       " ('closed_Is_quarter_start=true', 0.0),\n",
       " ('closed_Is_quarter_start=false', 0.0),\n",
       " ('closed_Is_year_end=true', 0.0),\n",
       " ('closed_Is_year_end=false', 0.0),\n",
       " ('created_Is_quarter_start=true', 0.0),\n",
       " ('created_Is_quarter_start=false', 0.0),\n",
       " ('closed_Dayofweek=5.0', 0.0),\n",
       " ('closed_Dayofweek=4.0', 0.0),\n",
       " ('closed_Dayofweek=3.0', 0.0),\n",
       " ('closed_Dayofweek=2.0', 0.0),\n",
       " ('closed_Dayofweek=1.0', 0.0),\n",
       " ('closed_Dayofweek=0.0', 0.0),\n",
       " ('created_Year=2015', 0.0),\n",
       " ('due_Year=2021.0', 0.0),\n",
       " ('due_Year=2020.0', 0.0),\n",
       " ('due_Year=2019.0', 0.0),\n",
       " ('due_Year=2017.0', 0.0),\n",
       " ('due_Year=2016.0', 0.0),\n",
       " ('due_Year=2015.0', 0.0),\n",
       " ('due_Year=2014.0', 0.0),\n",
       " ('created_Is_month_start=false', 0.0)]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(zip(train_x.columns[indices], importances[indices]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop Features that aren't Important"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_cols_loc = np.where(importances < 1e-6)[0]\n",
    "drop_cols = list(np.array(train_x.columns)[drop_cols_loc])\n",
    "train_x = train_x.drop(columns=drop_cols)\n",
    "test_x = test_x.drop(columns=drop_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1583727, 73)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "                       max_depth=4, max_features='auto', max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=10,\n",
       "                       n_jobs=None, oob_score=False, random_state=45, verbose=0,\n",
       "                       warm_start=False)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:\n",
      "Random Forest: 0.3843, Mode: 0.0812\n"
     ]
    }
   ],
   "source": [
    "preds = clf.predict(test_x)\n",
    "correct_loc = np.where(preds == test_y)[0]\n",
    "perc_correct = len(correct_loc) / len(preds)\n",
    "perc_correct_naive = len(np.where(test_y == mode(test_y)[0][0])[0]) / len(test_y)\n",
    "print('Accuracy:')\n",
    "print(f'Random Forest: {round(perc_correct, 4)}, Mode: {round(perc_correct_naive, 4)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Down Sample Data for Speed Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x['target'] = train_y\n",
    "x_train = train_x.sample(frac=0.1, replace=False)\n",
    "y_train = x_train['target']\n",
    "x_train = x_train.drop(columns=['target'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vary Number of Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num Trees: 50\n",
      "[0.391306 0.399848 0.384107]\n",
      "Num Trees: 100\n",
      "[0.396151 0.405488 0.393057]\n",
      "Num Trees: 150\n",
      "[0.416462 0.40443  0.406666]\n",
      "Num Trees: 200\n",
      "[0.426623 0.425043 0.407703]\n",
      "Best num trees:  200\n"
     ]
    }
   ],
   "source": [
    "n_trees = [50, 100, 150, 200]\n",
    "\n",
    "tree_scores = []\n",
    "for t in n_trees:\n",
    "    print(f'Num Trees: {t}')\n",
    "    rf = RandomForestClassifier(max_depth=depth[0], n_estimators=t, class_weight=\"balanced_subsample\")\n",
    "    cross_val = cross_val_score(rf, x_train, y_train, cv=3, scoring=\"balanced_accuracy\")\n",
    "    print(cross_val)\n",
    "    tree_scores.append(cross_val)\n",
    "tree_scores = np.array(tree_scores)\n",
    "np.save(\"tree_scores\", tree_scores)\n",
    "tree_avg = np.mean(tree_scores, axis=1)\n",
    "idx = np.argmax(tree_avg)\n",
    "num_trees = n_trees[idx]\n",
    "print(\"Best num trees: \", num_trees)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vary Tree Depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Depth: 4\n",
      "[0.373872 0.392568 0.366777]\n",
      "Depth: 8\n",
      "[0.4994   0.494036 0.481254]\n",
      "Depth: 12\n",
      "[0.549855 0.540086 0.549453]\n",
      "Depth: 16\n",
      "[0.553707 0.549908 0.553146]\n",
      "Best depth:  16\n"
     ]
    }
   ],
   "source": [
    "depth_scores = []\n",
    "for d in depth:\n",
    "    print(f\"Depth: {d}\")\n",
    "    rf = RandomForestClassifier(max_depth=d, n_estimators=50, class_weight=\"balanced_subsample\")\n",
    "    cross_val = cross_val_score(rf, x_train, y_train, cv=3, scoring=\"balanced_accuracy\")\n",
    "    print(cross_val)\n",
    "    depth_scores.append(cross_val)\n",
    "depth_scores = np.array(depth_scores)\n",
    "np.save(\"depth_scores\", depth_scores)\n",
    "depth_avg = np.mean(depth_scores, axis=1)\n",
    "idx = np.argmax(depth_avg)\n",
    "print(\"Best depth: \", depth[idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Double Check Number of Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num Trees: 50\n",
      "[0.551502 0.545424 0.54451 ]\n",
      "Num Trees: 100\n",
      "[0.555039 0.547201 0.548143]\n",
      "Best num trees:  100\n"
     ]
    }
   ],
   "source": [
    "n_trees = [50, 100]\n",
    "\n",
    "tree_scores = []\n",
    "for t in n_trees:\n",
    "    print(f'Num Trees: {t}')\n",
    "    rf = RandomForestClassifier(max_depth=12, n_estimators=t, class_weight=\"balanced_subsample\")\n",
    "    cross_val = cross_val_score(rf, x_train, y_train, cv=3, scoring=\"balanced_accuracy\")\n",
    "    print(cross_val)\n",
    "    tree_scores.append(cross_val)\n",
    "tree_scores = np.array(tree_scores)\n",
    "tree_avg = np.mean(tree_scores, axis=1)\n",
    "idx = np.argmax(tree_avg)\n",
    "num_trees = n_trees[idx]\n",
    "print(\"Best num trees: \", num_trees)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply New Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x, test_x, train_y, test_y = train_test_split(x, y, test_size=0.2, random_state=seed)\n",
    "clf = RandomForestClassifier(max_depth=12, n_estimators=50, random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = train_x.drop(columns=drop_cols)\n",
    "test_x = test_x.drop(columns=drop_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "                       max_depth=12, max_features='auto', max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=50,\n",
       "                       n_jobs=None, oob_score=False, random_state=45, verbose=0,\n",
       "                       warm_start=False)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:\n",
      "Random Forest: 0.6386\n"
     ]
    }
   ],
   "source": [
    "preds = clf.predict(test_x)\n",
    "correct_loc = np.where(preds == test_y)[0]\n",
    "perc_correct = len(correct_loc) / len(preds)\n",
    "print('Accuracy:')\n",
    "print(f'Random Forest: {round(perc_correct, 4)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Date Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_filt = (x['created_Year=2018'] == 1) | (x['created_Year=2019'] == 1)\n",
    "val_x = x.loc[val_filt]\n",
    "val_y = y[val_filt]\n",
    "val_x.shape, val_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_filt = ( \n",
    "    (df['created_Year=2010'] == 1) | \n",
    "    (df['created_Year=2011'] == 1) | \n",
    "    (df['created_Year=2012'] == 1) |\n",
    "    (df['created_Year=2013'] == 1) |\n",
    "    (df['created_Year=2014'] == 1) |\n",
    "    (df['created_Year=2015'] == 1) |\n",
    "    (df['created_Year=2016'] == 1) |\n",
    "    (df['created_Year=2017'] == 1) \n",
    ")\n",
    "trn_x = x.loc[trn_filt]\n",
    "trn_y = y[trn_filt]\n",
    "trn_x.shape, trn_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_x = trn_x.drop(columns=drop_cols)\n",
    "val_x = val_x.drop(columns=drop_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier(max_depth=12, n_estimators=50, random_state=seed)\n",
    "clf.fit(trn_x, trn_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
    "                       max_depth=12, max_features='auto', max_leaf_nodes=None,\n",
    "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "                       min_samples_leaf=1, min_samples_split=2,\n",
    "                       min_weight_fraction_leaf=0.0, n_estimators=50,\n",
    "                       n_jobs=None, oob_score=False, random_state=45, verbose=0,\n",
    "                       warm_start=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = clf.predict(val_x)\n",
    "correct_loc = np.where(preds == val_y)[0]\n",
    "perc_correct = len(correct_loc) / len(preds)\n",
    "print('Accuracy:')\n",
    "print(f'Random Forest: {round(perc_correct, 4)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Accuracy:\n",
    "Random Forest: 0.578"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy suffers but also missing data where created_Year = NaN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Next Steps\n",
    "- Look at confusion matrix \n",
    "- Try combining categories, i.e. Noise - Street/Sidewalk', 'Noise - Vehicle',\n",
    "- Search other hyperparameters (max_features, etc) using a randomized search, RandomizedSearchCV \n",
    "- Experiment with different ways to handle categorical, try nn.Embeddings\n",
    "- Figure out why fastai over trains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
